@misc{Acronis,
author = {Acronis},
booktitle = {Acronis},
title = {{Google Cloud Platform: Qu{\'{e}} es, c{\'{o}}mo se usa y c{\'{o}}mo se compara}},
url = {https://www.acronis.com/es-es/articles/google-cloud-platform/},
urldate = {2020-10-15}
}
@book{Geron2019,
abstract = {Second edition. "2nd edition updated for TensorFlow 2"--Page 1 of cover. Includes index. Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. The updated edition of this best-selling book uses concrete examples, minimal theory, and two production-ready Python frameworks-Scikit-Learn and TensorFlow 2-to help you gain an intuitive understanding of the concepts and tools for building intelligent systems. Practitioners will learn a range of techniques that they can quickly put to use on the job. Part 1 employs Scikit-Learn to introduce fundamental machine learning tasks, such as simple linear regression. Part 2, which has been significantly updated, employs Keras and TensorFlow 2 to guide the reader through more advanced machine learning methods using deep neural networks. With exercises in each chapter to help you apply what you've learned, all you need is programming experience to get started. NEW FOR THE SECOND EDITION:Updated all code to TensorFlow 2 ; Introduced the high-level Keras API ; New and expanded coverage including TensorFlow's Data API, Eager Execution, Estimators API, deploying on Google Cloud ML, handling time series, embeddings and more With Early Release ebooks, you get books in their earliest form-the author's raw and unedited content as he or she writes-so you can take advantage of these technologies long before the official release of these titles. You'll also receive updates when significant changes are made, new chapters are available, and the final ebook bundle is released. Part I, The fundamentals of machine learning. The machine learning landscape ; End-to-end machine learning project ; Classification ; Training models ; Support vector machines ; Decision trees ; Ensemble learning and random forests ; Dimensionality reduction ; Unsupervised learning techniques -- Part II, Neural networks and deep learning. Introduction to artificial neural networks with Keras ; Training deep neural networks ; Custom models and training with TensorFlow ; Loading and preprocessing data with TensorFlow ; Deep computer vision using convolutional neural networks ; Processing sequences using RNNs and CNNs ; Natural language processing with RNNs and attention ; Representation learning and generative learning using autoencoders and GANs ; Reinforcement learning ; Training and deploying TensorFlow models at scale ; Exercise solutions ; Machine learning project checklist ; SVM dual problem ; Autodiff ; Other popular ANN architectures ; Special data structures ; TensorFlow graphs.},
author = {{Aur{\'{e}}lien G{\'{e}}ron}},
edition = {2},
isbn = {9781492032649},
pages = {851},
publisher = {O'Reilly},
title = {{Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems}},
url = {https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/},
year = {2019}
}
@book{Chazallet,
author = {Chazallet, Sebastien},
title = {{Python 3: Los fundamentos del lenguaje}}
}
@misc{Desconocido1928,
author = {Desconocido},
booktitle = {Wikimedia Commons},
title = {{Passport photo of Alan Turing at age 16}},
url = {https://commons.wikimedia.org/wiki/File:Alan{\_}Turing{\_}Aged{\_}16.jpg},
urldate = {2020-10-16},
year = {1928}
}
@misc{Diez2019,
author = {Diez, Pablo M.},
booktitle = {ABC},
title = {{El «Gran Hermano» chino lo ve todo con c{\'{a}}maras que reconocen caras en segundos}},
url = {https://www.abc.es/sociedad/abci-gran-hermano-chino-todo-camaras-reconocen-caras-segundos-201905190159{\_}noticia.html?ref=https:{\%}2F{\%}2Fwww.google.es{\%}2F},
urldate = {2020-10-15},
year = {2019}
}
@misc{DomingoMunoz2017,
author = {{Domingo Mu{\~{n}}oz}, Jos{\'{e}}},
booktitle = {OpenWebinars},
title = {{Qu{\'{e}} es Flask y ventajas que ofrece}},
url = {https://openwebinars.net/blog/que-es-flask/},
urldate = {2020-10-15},
year = {2017}
}
@book{EditorialSalvat2006,
author = {{Editorial Salvat}},
pages = {288},
title = {{Historia del Arte: El realismo. El impresionismo.}},
year = {2006}
}
@book{Foster2019,
abstract = {First edition. With Early Release ebooks, you get books in their earliest form-the author's raw and unedited content as he or she writes-so you can take advantage of these technologies long before the official release of these titles. You'll also receive updates when significant changes are made, new chapters are available, and the final ebook bundle is released. Generative modeling is one of the hottest topics in artificial intelligence. Recent advances in the field have shown how it's possible to teach a machine to excel at human endeavors-such as drawing, composing music, and completing tasks by generating a world model to understand how its actions affect its environment. With this practical book, machine learning engineers and data scientists will learn how to recreate some of the most famous examples of generative deep learning models, such as variational autoencoders and generative adversarial networks (GANs). You'll also learn how to apply the techniques to your own datasets. David Foster, cofounder of Applied Data Science, demonstrates the inner workings of each technique, starting with the basics of deep learning before advancing to the most cutting-edge algorithms in the field. Through tips and tricks, you'll learn how to make your models learn more efficiently and become more creative. Get a fundamental overview of deep learning Learn about libraries such as Keras and TensorFlow Discover how variational autoencoders work Get practical examples of generative adversarial networks (GANs) Understand how autoregressive generative models function Apply generative models within a reinforcement learning setting to accomplish tasks. Part 1. Introduction to generative deep learning. Generative modeling -- Deep learning -- Variational autoencoders -- Generative adversarial networks -- Part 2. Teaching machines to paint, write, compose, and play. Paint -- Write -- Compose -- Play -- The future of generative modeling -- Conclusion.},
author = {Foster, David and Safari, an O'Reilly Media Company.},
edition = {1},
isbn = {9781492041948},
pages = {308},
publisher = {O'Reilly},
title = {{Generative deep learning : teaching machines to paint, write, compose, and play}},
year = {2019}
}
@misc{Garcia2017,
author = {Garcia, Toni},
booktitle = {El Mundo},
title = {{¿Puede crear arte una m{\'{a}}quina?}},
url = {https://www.elmundo.es/papel/pantallas/2017/01/05/586a361046163f05748b4576.html},
urldate = {2020-10-15},
year = {2017}
}
@misc{Guru99,
author = {Guru99},
booktitle = {Guru99},
title = {{Tutorial de Tensorboard: Visualizaci{\'{o}}n de gr{\'{a}}ficos con ejemplo}},
url = {https://guru99.es/tensorboard-tutorial/},
urldate = {2020-10-15}
}
@misc{LozanoGomez,
author = {{Lozano G{\'{o}}mez}, Juan Jos{\'{e}}},
booktitle = {J2logo},
title = {{Tutorial de c{\'{o}}mo crear un API REST en Python con Flask}},
url = {https://j2logo.com/flask/tutorial-como-crear-api-rest-python-con-flask/},
urldate = {2020-10-15}
}
@misc{Metz2016,
author = {Metz, Cade},
booktitle = {Wired},
title = {{Google's AI Wins Fifth And Final Game Against Go Genius Lee Sedol}},
url = {https://www.wired.com/2016/03/googles-ai-wins-fifth-final-game-go-genius-lee-sedol/},
urldate = {2020-10-15},
year = {2016}
}
@misc{NVIDIA,
author = {NVIDIA},
booktitle = {NVIDIA},
title = {{CUDA Zone}},
url = {https://developer.nvidia.com/cuda-zone},
urldate = {2020-10-15}
}
@article{PerezRepresa2016,
author = {{P{\'{e}}rez Represa}, C{\'{e}}sar and {C{\'{a}}mara Nebreda}, Jos{\'{e}} Mar{\'{i}}a and {S{\'{a}}nchez Ortega}, Pedro Luis},
file = {:home/victor/Almacen/Documentos/Universidad/Year 3/Segundo Cuatrimestre/Arquitecturas Avanzadas/Arquitecturas Avanzadas/Programacion{\_}en{\_}CUDA (2).pdf:pdf},
pages = {74},
title = {{Introducci{\'{o}}n a la programaci{\'{o}}n en CUDA}},
year = {2016}
}
@article{Sajjadi2016,
archivePrefix = {arXiv},
arxivId = {1612.07919},
author = {Sajjadi, Mehdi S. M. and Sch{\"{o}}lkopf, Bernhard and Hirsch, Michael},
eprint = {1612.07919},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sajjadi, Sch{\"{o}}lkopf, Hirsch - 2016 - EnhanceNet Single Image Super-Resolution Through Automated Texture Synthesis.pdf:pdf},
month = {dec},
title = {{EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis}},
url = {https://arxiv.org/abs/1612.07919},
year = {2016}
}
@misc{Sanseviero2019,
author = {Sanseviero, Omar},
booktitle = {AI Learners},
month = {mar},
title = {{Introducci{\'{o}}n a TensorFlow (Parte 1) | by Omar Sanseviero | AI Learners | Medium}},
url = {https://medium.com/ai-learners/introducci{\'{o}}n-a-tensorflow-parte-1-840c01881658},
urldate = {2020-10-15},
year = {2019}
}
@misc{Serradilla2017,
author = {Serradilla, Francisco},
month = {feb},
title = {{¿Pueden crear las m{\'{a}}quinas? Quiz{\'{a}}s te sorprenda la respuesta}},
url = {https://blogthinkbig.com/pueden-crear-las-maquinas},
urldate = {2020-10-15},
year = {2017}
}
@article{Zhu2017,
archivePrefix = {arXiv},
arxivId = {1703.10593},
author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
eprint = {1703.10593},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2017 - Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.pdf:pdf},
month = {mar},
title = {{Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}},
url = {https://arxiv.org/abs/1703.10593},
year = {2017}
}
@misc{Monet1873,
author = {Monet, Claude},
booktitle = {Mus{\'{e}}e Marmottan Monet},
keywords = {Francia,arte,impresionismo},
mendeley-groups = {TFG Impresionismo},
title = {{Impresi{\'{o}}n, Sol Naciente}},
url = {https://commons.wikimedia.org/wiki/File:Monet{\_}-{\_}Impression,{\_}Sunrise.jpg},
urldate = {2020-10-16},
year = {1873}
}
@article{Aldana2019,
author = {Aldana, Bel{\'{e}}n Garc{\'{i}}a-Botija},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/TFG ajenos/TFG{\_}BELEN{\_}GARCIA{\_}BOTIJA{\_}ALDANA.pdf:pdf},
journal = {Escuela T{\'{e}}cnica Superior de Ingenieros de Sistemas Inform{\'{a}}ticos (Universidad Polit{\'{e}}cnica de Madrid)},
keywords = {ETSISI},
mendeley-groups = {TFG Impresionismo},
pages = {52},
title = {{Diagn{\'{o}}stico de la enfermedad de Parkinson usando deep learning y grabaciones de voz mediante tel{\'{e}}fono m{\'{o}}vil}},
year = {2019}
}
@misc{Monet1886,
author = {Monet, Claude},
booktitle = {Mus{\'{e}}e d'Orsay},
mendeley-groups = {TFG Impresionismo},
title = {{Mujer con sombrilla mirando a la izquierda}},
url = {https://commons.wikimedia.org/wiki/File:Claude{\_}Monet{\_}023.jpg},
urldate = {2020-10-16},
year = {1886}
}
@misc{Manet1863,
author = {Manet, {\'{E}}douard},
booktitle = {Mus{\'{e}}e d'Orsay},
mendeley-groups = {TFG Impresionismo},
title = {{Almuerzo sobre la hierba}},
url = {https://commons.wikimedia.org/wiki/File:Edouard{\_}Manet{\_}-{\_}Luncheon{\_}on{\_}the{\_}Grass{\_}-{\_}Google{\_}Art{\_}Project.jpg},
urldate = {2020-10-16},
year = {1863}
}
@misc{Cezanne1893,
author = {C{\'{e}}zanne, Paul},
booktitle = {Colecci{\'{o}}n privada de la familia real de Catar},
mendeley-groups = {TFG Impresionismo},
title = {{Los Jugadores de cartas}},
url = {https://commons.wikimedia.org/wiki/File:Les{\_}Joueurs{\_}de{\_}cartes,{\_}par{\_}Paul{\_}C{\'{e}}zanne,{\_}collection{\_}Al-Thani,{\_}Yorck.jpg},
urldate = {2020-10-16},
year = {1893}
}
@misc{Cezanne1878,
author = {C{\'{e}}zanne, Paul},
mendeley-groups = {TFG Impresionismo},
title = {{El Sena en Bercy}},
url = {https://commons.wikimedia.org/wiki/File:Paul-Cezanne-The-Seine-at-Bercy.jpg},
urldate = {2020-10-16},
year = {1878}
}
@misc{Gogh1889,
author = {Gogh, Van},
booktitle = {Mus{\'{e}}e d'Orsay},
mendeley-groups = {TFG Impresionismo},
title = {{Autorretrato}},
url = {https://commons.wikimedia.org/wiki/File:SelbstPortrait{\_}VG2.jpg},
urldate = {2020-10-16},
year = {1889}
}
@misc{VanGogh1889,
author = {{Van Gogh}, Vicent},
booktitle = {Museum of Modern Art},
mendeley-groups = {TFG Impresionismo},
title = {{La noche estrellada}},
url = {https://commons.wikimedia.org/wiki/File:Van{\_}Gogh{\_}-{\_}Starry{\_}Night{\_}-{\_}Google{\_}Art{\_}Project.jpg},
urldate = {2020-10-17},
year = {1889}
}
@misc{Monet1867,
author = {Monet, Claude},
booktitle = {Metropolitan Museum of Art},
mendeley-groups = {TFG Impresionismo},
title = {{La terraza de Sainte-Adresse}},
url = {https://commons.wikimedia.org/wiki/File:Monet{\_}-Terrasse{\_}am{\_}Meeresufer{\_}von{\_}Sainte{\_}Adresse.jpg},
urldate = {2020-10-16},
year = {1867}
}
@misc{Todocuadros,
author = {Todocuadros},
booktitle = {Todocuadros},
mendeley-groups = {TFG Impresionismo},
title = {{Impresionismo, pintura, historia y cuadros impresionistas.}},
url = {https://www.todocuadros.es/estilos-arte/impresionismo/},
urldate = {2020-10-16}
}


@misc{Millet1857,
author = {Millet, Jean-Fran{\c{c}}ois},
booktitle = {Mus{\'{e}}e d'Orsay},
keywords = {Realismo},
mendeley-groups = {TFG Impresionismo},
title = {{Las espigadoras}},
url = {https://commons.wikimedia.org/wiki/File:Jean-Fran{\c{c}}ois{\_}Millet{\_}-{\_}Gleaners{\_}-{\_}Google{\_}Art{\_}Project.jpg},
urldate = {2020-10-16},
year = {1857}
}
@misc{Hals1648,
author = {Hals, Frans},
booktitle = {Museo Nacional Thyssen-Bornemisza},
keywords = {holanda,pintura holandesa del siglo xvii},
mendeley-groups = {TFG Impresionismo},
title = {{Grupo familiar ante un paisaje}},
url = {https://es.wikipedia.org/wiki/Archivo:Frans{\_}Hals{\_}-{\_}Family{\_}Group{\_}in{\_}a{\_}Landscape{\_}-{\_}WGA11154.jpg},
urldate = {2020-10-16},
year = {1648}
}

@misc{Sienra2019,
author = {Sienra, Regina},
booktitle = {mymodernmet},
mendeley-groups = {TFG Impresionismo},
title = {{¿Qu{\'{e}} es el impresionismo? Ejemplos y definici{\'{o}}n del impresionismo}},
url = {https://mymodernmet.com/es/que-es-impresionismo-definicion/},
urldate = {2020-10-16},
year = {2019}
}
@misc{Renoir1875,
author = {Renoir, Auguste},
booktitle = {Mus{\'{e}}e d'Orsay},
mendeley-groups = {TFG Impresionismo},
title = {{Retrato de Claude Monet}},
url = {https://commons.wikimedia.org/wiki/File:Auguste{\_}Renoir{\_}-{\_}Claude{\_}Monet{\_}-{\_}Google{\_}Art{\_}Project.jpg},
urldate = {2020-10-17},
year = {1875}
}
@misc{CalvoSantos2016,
author = {{Calvo Santos}, Miguel},
booktitle = {HA!},
mendeley-groups = {TFG Impresionismo},
month = {sep},
title = {{Vincent Van Gogh}},
url = {https://historia-arte.com/artistas/vincent-van-gogh},
urldate = {2020-10-17},
year = {2016}
}
@misc{CalvoSantos2016-2,
author = {{Calvo Santos}, Miguel},
booktitle = {HA!},
mendeley-groups = {TFG Impresionismo},
month = {sep},
title = {{Claude Monet}},
url = {https://historia-arte.com/artistas/claude-monet},
urldate = {2020-10-17},
year = {2016}
}
@misc{Barreira2019,
author = {Barreira, D},
booktitle = {El Espa{\~{n}}ol},
mendeley-groups = {TFG Impresionismo},
month = {jun},
title = {{Las inc{\'{o}}gnitas sobre la muerte de Van Gogh: ¿se suicid{\'{o}} de un disparo o lo asesinaron?}},
url = {https://www.elespanol.com/cultura/20190618/incognitas-muerte-van-gogh-suicido-disparo-asesinaron/407209991{\_}0.html},
urldate = {2020-10-17},
year = {2019}
}
@misc{Cezanne1894,
author = {Cezanne, Paul},
booktitle = {Bridgestone Museum of Art},
mendeley-groups = {TFG Impresionismo},
title = {{Autorretrato con sombrero arrugado}},
url = {https://commons.wikimedia.org/wiki/File:Paul{\_}Cezanne{\_}-{\_}Self-Portrait{\_}with{\_}a{\_}Hat{\_}-{\_}Google{\_}Art{\_}Project.jpg},
urldate = {2020-10-17},
year = {1894}
}
@misc{CalvoSantos2016-3,
author = {{Calvo Santos}, Miguel},
booktitle = {HA!},
mendeley-groups = {TFG Impresionismo},
month = {sep},
title = {{Paul C{\'{e}}zanne }},
url = {https://historia-arte.com/artistas/paul-cezanne},
urldate = {2020-10-17},
year = {2016}
}
@misc{WikiquoteCezanne,
author = {Wikiquote},
booktitle = {Wikiquote},
mendeley-groups = {TFG Impresionismo},
title = {{Paul C{\'{e}}zanne}},
url = {https://es.wikiquote.org/wiki/Paul{\_}C{\'{e}}zanne{\#}cite{\_}note-vanguardia-7},
urldate = {2020-10-17}
}
@misc{ElizaldeOcampo2020,
author = {{Elizalde Ocampo}, Elsa Mar{\'{i}}a},
booktitle = {Pico Informativo},
mendeley-groups = {TFG Impresionismo},
title = {{Paul C{\'{e}}zanne: “el padre de todos nosotros”}},
url = {https://picoinformativo.com/sin-categoria/paul-cezanne-el-padre-de-todos-nosotros/},
urldate = {2020-10-17},
year = {2020}
}
@misc{EFE2016,
author = {EFE},
booktitle = {El Mundo},
mendeley-groups = {TFG Impresionismo},
month = {jul},
title = {{El {\'{o}}leo 'Lot y sus hijas', de Rubens, subastado por 52,4 millones de euros}},
url = {https://www.elmundo.es/cultura/2016/07/08/577f6d8422601ddf118b4591.html},
urldate = {2020-10-17},
year = {2016}
}

@article{Garcia2012,
author = {{Serradilla Garc{\'{i}}a}, Francisco},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/Transparencias Inteligencia Artificial/IntroIA.pdf:pdf},
mendeley-groups = {TFG Impresionismo},
title = {{Trasparencias de Introducci{\'{o}}n a la Inteligencia Artificial}},
year = {2012}
}

@misc{Pastor2018,
author = {Pastor, Javier},
booktitle = {Xataka},
mendeley-groups = {TFG Impresionismo},
title = {{Qu{\'{e}} es la inteligencia artificial}},
url = {https://www.xataka.com/robotica-e-ia/que-inteligencia-artificial},
urldate = {2020-10-17},
year = {2018}
}

@book{PonceCruz2010,
abstract = {Presenta algunas ideas en torno a la noci{\'{o}}n de inteligencia que nos ayuden a identificar ciertas caracteristicas distintivas de la denominada inteligencia artificial.},
author = {{Ponce Cruz}, Pedro},
booktitle = {Alfaomega, M{\'{e}}xico},
file = {:home/victor/Almacen/Libros T{\'{e}}cnicos/IA/inteligencia-artificial-con-aplicaciones-a-la-ingenierc3ada.pdf:pdf},
isbn = {9786077854838},
mendeley-groups = {TFG Impresionismo},
pages = {376},
title = {{Inteligencia Artificial con aplicaciones a la ingenier{\'{i}}a}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Inteligencia+artificial+con+aplicaciones+a+la+ingenier�a{\#}0},
year = {2010}
}
@article{EchegoyenBlanco2017,
author = {{Echegoyen Blanco}, Guillermo},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/TFG{\_}GUILLERMO{\_}ECHEGOYEN{\_}BLANCO.pdf:pdf},
journal = {Escuela T{\'{e}}cnica Superior de Ingenieros de Sistemas Inform{\'{a}}ticos (Universidad Polit{\'{e}}cnica de Madrid)},
mendeley-groups = {TFG Impresionismo},
title = {{A Neural Networks Benchmark for Image Classification}},
year = {2017}
}
@article{SerradillaGarcia2016,
author = {{Serradilla Garc{\'{i}}a}, Francisco},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/Transparencias Inteligencia Artificial/Redes de Neuronas.pdf:pdf},
mendeley-groups = {TFG Impresionismo},
title = {{Aprendizaje Autom{\'{a}}tico Redes de Neuronas}},
year = {2016}
}
@misc{Balaji2019,
author = {Balaji, Sabari},
booktitle = {Sabari Balaji},
mendeley-groups = {TFG Impresionismo},
title = {{Overfitting. Overfitting overview}},
url = {https://medium.com/@cs.sabaribalaji/overfitting-6c1cd9af589},
urldate = {2020-10-17},
year = {2019}
}
@misc{Mendoza2019,
author = {Mendoza, Ricardo},
booktitle = {Ricardo Mendoza},
mendeley-groups = {TFG Impresionismo},
title = {{Entendiendo las Redes Neuronales Artificiales}},
url = {https://medium.com/@ricardojmv85/entendiendo-las-redes-neuronales-artificiales-1e0f4523eae6},
urldate = {2020-10-18},
year = {2019}
}
@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Kzrak2019,
author = {Kızrak, Ayy{\"{u}}ce},
booktitle = {Towards Data Science},
mendeley-groups = {TFG Impresionismo},
month = {may},
title = {{Comparison of Activation Functions for Deep Neural Networks }},
url = {https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a},
urldate = {2020-10-18},
year = {2019}
}

@book{Rusell2004,
abstract = {O livro visa cobrir uma variedade de t{\'{e}}cnicas de Intelig{\^{e}}ncia Artificial, algoritmos e metodologias, incluindo playing game, agentes inteligentes, aprendizado de m{\'{a}}quinas, algoritmos gen{\'{e}}ticos e vida artificial. O autor concentra-se em explicar como t{\'{e}}cnicas de Intelig{\^{e}}ncia Artificial se relacionam e s{\~{a}}o derivadas de sistemas naturais, tais como o c{\'{e}}rebro humano e a pr{\'{o}}pria evolu{\c{c}}{\~{a}}o das esp{\'{e}}cies, buscando explicar como os equivalentes artificiais s{\~{a}}o utilizados no mundo real. Cada cap{\'{i}}tulo inclui uma introdu{\c{c}}{\~{a}}o, explicando o que ser{\'{a}} abordado, um resumo do cap{\'{i}}tulo, alguns exerc{\'{i}}cios e quest{\~{o}}es para revis{\~{a}}o, bem como sugest{\~{o}}es para leitura adicional. H{\'{a}} uma bibliografia no final do livro, al{\'{e}}m de um gloss{\'{a}}rio incluindo breves defini{\c{c}}{\~{o}}es de certos termos.},
author = {Rusell, Stuart and Norvig, Peter},
booktitle = {Inteligencia Artificial},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/inteligencia-artificial-un-enfoque-moderno-stuart-j-russell.pdf:pdf},
isbn = {0137903952},
issn = {19883064},
keywords = {caso de los humanos,computadores,de s{\'{i}}mbolos f{\'{i}}sicos,el caso de los,electr{\'{o}}nicos y en el,en el caso de,humanos mediante redes neuronales,los,los computadores los s{\'{i}}mbolos,los s{\'{i}}mbolos se realizan,mediante circuitos electr{\'{o}}nicos digitales,son f{\'{i}}sico-,son f{\'{i}}sico-biol{\'{o}}gico,y en},
pages = {1--1213},
title = {{Inteligencia Artificial. Un Enfoque Moderno}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Inteligencia+Artificial:+un+enfoque+moderno{\#}0},
year = {2004}
}

@misc{Kang2017,
author = {Kang, Nahua},
booktitle = {Towards Data Science},
mendeley-groups = {TFG Impresionismo},
month = {jun},
title = {{Multi-Layer Neural Networks with Sigmoid Function}},
url = {https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f},
urldate = {2020-10-18},
year = {2017}
}

@article{Hilton1986,
author = {Hilton, Geoffrey and Rumelhart, David and Williams, Ronald},
doi = {10.1038/323533a0},
file = {:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/nnet1.pdf:pdf},
journal = {Nature Biotechnology},
title = {{Learning representations by back-propagating errors}},
year = {1986}
}

@report{Fukushima1980,
   abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells', which show characteristics similar to simple cells or lower order hyper-complex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
   author = {Kunihiko Fukushima},
   journal = {Biol. Cybernetics},
   pages = {202},
   title = {Biological Cybernetics Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
   volume = {36},
   year = {1980}
}

@article{Hubel1959,
author = {Hubel, D H and Wiesel, T N},
doi = {10.1113/jphysiol.1959.sp006308},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubel, Wiesel - Unknown - 59I RECEPTIVE FIELDS OF SINGLE NEURONES IN THE CAT'S STRIATE CORTEX.pdf:pdf},
issn = {14697793},
journal = {The Journal of Physiology},
number = {3},
pages = {574--591},
pmid = {14403679},
title = {{Receptive fields of single neurones in the cat's striate cortex}},
volume = {148},
year = {1959}
}

@misc{Calvo2017,
author = {Calvo, Diego},
booktitle = {Diego Calvo},
mendeley-groups = {TFG Impresionismo},
month = {jul},
title = {{Red Neuronal Convolucional}},
url = {https://www.diegocalvo.es/red-neuronal-convolucional},
urldate = {2020-10-18},
year = {2020}
}

@inproceedings{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-24574-4_28},
eprint = {1505.04597},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - Unknown - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:pdf},
isbn = {9783319245737},
issn = {16113349},
pages = {234--241},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
url = {http://lmb.informatik.uni-freiburg.de/},
volume = {9351},
year = {2015}
}

@inproceedings{He2016,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - Unknown - Deep Residual Learning for Image Recognition.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
url = {http://image-net.org/challenges/LSVRC/2015/},
volume = {2016-Decem},
year = {2016}
}

@inproceedings{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661v1},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1406.2661v1},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - Unknown - Generative Adversarial Nets.pdf:pdf},
issn = {10495258},
mendeley-groups = {TFG Impresionismo},
number = {January},
pages = {2672--2680},
title = {{Generative Adversarial Nets}},
url = {http://www.github.com/goodfeli/adversarial},
volume = {3},
year = {2014}
}

@misc{Pescador2019,
author = {Pescador, Dar{\'{i}}o},
booktitle = {elDiario.es},
mendeley-groups = {TFG Impresionismo},
month = {aug},
title = {{C{\'{o}}mo te van a quitar tu trabajo los robots}},
url = {https://www.eldiario.es/comoyporque/van-quitar-trabajo-robots{\_}1{\_}1401726.html},
urldate = {2020-10-19},
year = {2019}
}
@misc{RamonRallo2019,
author = {{Ram{\'{o}}n Rallo}, Juan},
booktitle = {EL Confidencial},
mendeley-groups = {TFG Impresionismo},
month = {may},
title = {{Empleo: ¿Los robots nos est{\'{a}}n quitando el empleo?}},
url = {https://blogs.elconfidencial.com/economia/laissez-faire/2019-05-17/robots-quitar-empleo{\_}2005654/},
urldate = {2020-10-19},
year = {2019}
}
@misc{IBMDeveloperAdvocateinSiliconValley2019,
author = {{IBM Developer Advocate in Silicon Valley}},
booktitle = {Medium},
mendeley-groups = {TFG Impresionismo},
month = {dec},
title = {{Deepfakes and the world of Generative Adversarial Networks}},
url = {https://medium.com/@lennartfr/deepfakes-and-the-world-of-generative-adversarial-networks-bf6937e70637},
urldate = {2020-10-19},
year = {2019}
}
@misc{Roca2020,
author = {Roca, Josep},
booktitle = {hardware,es},
mendeley-groups = {TFG Impresionismo},
month = {sep},
title = {{NVIDIA ha comprado ARM: ventajas y desventajas para el usuario}},
url = {https://hardzone.es/tutoriales/rendimiento/problemas-yventajas-de-que-nvidia-compre-arm/},
urldate = {2020-10-19},
year = {2020}
}
@misc{ElPeriodicodelaEnergia2018,
author = {{El Periodico de la Energ{\'{i}}a}},
booktitle = {El Periodico de la Energ{\'{i}}a},
mendeley-groups = {TFG Impresionismo},
month = {jul},
title = {{Cobra (ACS) promueve una planta fotovoltaica de 49,88 MW en Galisteo (C{\'{a}}ceres) }},
url = {https://elperiodicodelaenergia.com/cobra-acs-promueve-una-planta-fotovoltaica-de-4988-mw-en-galisteo-caceres/},
urldate = {2020-10-19},
year = {2018}
}

@misc{R.VIllatoro2018,
author = {{R. VIllatoro}, Francisco},
booktitle = {La Ciencia de la Mula Francis},
mendeley-groups = {TFG Impresionismo},
month = {dec},
title = {{Caras humanas sint{\'{e}}ticas hiperrealistas usando redes generativas antag{\'{o}}nicas }},
url = {https://francis.naukas.com/2018/12/23/caras-humanas-sinteticas-hiperrealistas-usando-redes-generativas-antagonicas/},
urldate = {2020-10-19},
year = {2018}
}

@misc{Zavia2018,
author = {{S. Zavia}, Mat{\'{i}}as},
booktitle = {Gizmodo},
mendeley-groups = {TFG Impresionismo},
month = {dec},
title = {{¿Cu{\'{a}}l de estas personas es real y cu{\'{a}}l fue generada por una IA?}},
url = {https://es.gizmodo.com/puedes-adivinar-cual-de-estas-personas-es-real-y-cual-1831198517},
urldate = {2020-10-19},
year = {2018}
}

@misc{Neurohive2018,
author = {Neurohive},
booktitle = {Neurohive},
mendeley-groups = {TFG Impresionismo},
month = {oct},
title = {{VGG16 - Convolutional Network for Classification and Detection}},
url = {https://neurohive.io/en/popular-networks/vgg16/},
urldate = {2020-10-21},
year = {2018}
}
@techreport{Assens,
abstract = {We introduce PathGAN, a deep neural network for visual scanpath prediction trained on adversarial examples. A visual scanpath is defined as the sequence of fixation points over an image defined by a human observer with its gaze. PathGAN is composed of two parts, the generator and the discriminator. Both parts extract features from images using off-the-shelf networks, and train recurrent layers to generate or discriminate scanpaths accordingly. In scanpath prediction, the stochastic nature of the data makes it very difficult to generate realistic predictions using supervised learning strategies, but we adopt adversarial training as a suitable alternative. Our experiments prove how PathGAN improves the state of the art of visual scanpath prediction on the iSUN and Salient360! datasets.},
archivePrefix = {arXiv},
arxivId = {1809.00567v1},
author = {Assens, Marc and Giro-I-Nieto, Xavier and Mcguinness, Kevin and O'connor, Noel E},
eprint = {1809.00567v1},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Assens et al. - Unknown - PathGAN Visual Scanpath Prediction with Generative Adversarial Networks.pdf:pdf},
isbn = {1809.00567v1},
keywords = {GAN,adversarial training,cGAN,saliency,scanpath},
title = {{PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks}},
url = {https://github.com/imatge-upc/pathgan.}
}
@techreport{Turing1947,
author = {Turing, Alan M.},
file = {:home/victor/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - (No Title).pdf:pdf;:home/victor/Almacen/Documentos/Universidad/TFG/Computadores/Documentos/turing-vorlesung.pdf:pdf},
title = {{Lecture to the London Mathematieal Society on 20 February 1947}},
year = {1947}
}

@misc{StackOverflow2018,
author = {{Stack Overflow}},
booktitle = {Stack Overflow},
mendeley-groups = {TFG Impresionismo},
month = {jul},
title = {{Which TensorFlow and CUDA version combinations are compatible?}},
url = {https://stackoverflow.com/questions/50622525/which-tensorflow-and-cuda-version-combinations-are-compatible},
urldate = {2020-10-22},
year = {2018}
}
@misc{Tabora2020,
author = {Tabora, Vince},
booktitle = {High-Definition Pro},
mendeley-groups = {TFG Impresionismo},
month = {mar},
title = {{Bicubic Interpolation Techniques For Digital Imaging}},
url = {https://medium.com/hd-pro/bicubic-interpolation-techniques-for-digital-imaging-7c6d86dc35dc},
urldate = {2020-10-22},
year = {2020}
}
@misc{Rapole2020,
author = {Rapole, Shivani},
booktitle = {The Startup},
mendeley-groups = {TFG Impresionismo},
month = {aug},
title = {{EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis}},
url = {https://medium.com/swlh/enhancenet-single-image-super-resolution-through-automated-texture-synthesis-c0fe252d077d},
urldate = {2020-10-22},
year = {2020}
}
@misc{TensorFlow_Dataset,
author = {TensorFlow},
booktitle = {TensorFlow},
mendeley-groups = {TFG Impresionismo},
title = {{tf.data.Dataset}},
url = {https://www.tensorflow.org/api{\_}docs/python/tf/data/Dataset},
urldate = {2020-10-23}
}
